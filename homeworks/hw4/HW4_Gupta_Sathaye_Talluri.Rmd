---
title: "Homework 4"
subtitle: STAT 334
author: "Krishnanshu Gupta, Ishaan Sathaye, Sreshta Talluri"
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: readable
    highlight: haddock
    toc: true
    toc_float: true
    code_folding: hide  
---

```{r chunk setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      eval=TRUE,
                      message=FALSE,
                      warning=FALSE)
```

```{r packages, include=FALSE}
library(readxl)
setwd( dirname( rstudioapi::getActiveDocumentContext( )$path ) )
```

# Question 2

```{r cars}
love <- read_xls("./love.xls")
summary(love)
```

## Part (a)

```{r}
model <- lm(NGF ~ PLS + AGE, data = love)
summary(model)
```

For every one point increase in PLS score, the predicted NGF levels will increase by 2.77, after adjusting for AGE.

## Part (b)

**Null Hypothesis (H0):** $\beta_1$, $\beta_2$ = 0

**Alternate Hypothesis (H1):** At least one of $\beta_1$ or $\beta_2$ $\neq$ 0

$\beta_1$ is the coefficient for PLS score and $\beta_2$ is the coefficient for AGE

**Test Statistic:** F-statistic = 3.774, DF = 58 - 3 = 55

p-value = 0.02911

**Conclusion:** Based on the small p-value of 0.02911, we have sufficient evidence to reject the Null Hypothesis. We have fairly strong evidence to suggest that at least one of the predictors, PLS score or AGE, is a significant predictor of NGF levels. This suggests that including these predictors in the model provides a better fit for explaining the variability in NGF levels compared to a model without these predictors.

## Part (c)

**Null Hypothesis (H0):** $\beta_1$ = 0

**Alternate Hypothesis (H1):** $\beta_1$ \> 0

$\beta_1$ is the coefficient for PLS score

**Test Statistic:** t = 2.739, DF = 58 - 3 = 55

p-value = 0.00828 / 2 = 0.00414 (we divide by 2 since it is a one-sided test)

**Conclusion:** Based on the small p-value of 0.00414, we have sufficient evidence to reject the Null Hypothesis. We have very strong evidence of a positive association between PLS score and NGF level, where an increase in PLS score is associated with an increase in NGF level, after adjusting for AGE.

## Part (d)

**Null Hypothesis (H0):** The inclusion of BDI, STAI, and YBOCS does not significantly improve the model's explanatory power beyond what is provided by PLS and AGE. This implies that coefficients for BDI, STAI, and YBOCS in the extended model are all 0. ($\beta_3$, $\beta_4$, $\beta_5$ = 0)

**Alternate Hypothesis (H1):** The inclusion of BDI, STAI, and YBOCS provides a significant improvement in the model's explanatory power. (At least one of $\beta_3$, $\beta_4$, $\beta_5$ $\neq$ 0)

```{r}
extended_model <- lm(NGF ~ PLS + AGE + BDI + STAI + YBOCS, data = love)

# Perform an ANOVA to compare the two models
anova(model, extended_model)
```

**Test Statistic:** F-statistic = 1.3426

**DF:** Model DF = 55; Extended Model DF = 52; Difference in DF = 3

p-value = 0.2707

**Conclusion:** Given the F-statistic of 1.3426 and a p-value of 0.2707, we fail to reject the null hypothesis at a typical alpha level of 0.05. The p-value of 0.2707 indicates that we have insufficient statistical evidence to conclude that the psychiatric rating scales (BDI, STAI, and YBOCS) contribute additional explanatory power to the relationship between NGF levels and the initial predictors (PLS and AGE).

## Part (e)

```{r}
# Adjusted R-squared for the initial model
summary(model)$adj.r.squared

# Adjusted R-squared for the extended model with STAI (only adding STAI for comparison)
model_with_stai <- lm(NGF ~ PLS + AGE + STAI, data = love)
summary(model_with_stai)$adj.r.squared
```

The original model (not including STAI) has a higher adjusted R-squared (0.0887) compared to the new model which includes STAI (0.0729). This indicates that the original model actually explains a slightly larger proportion of the variance in NGF level compared to the new model which includes STAI.

This could be due to the fact that the variance related to NGF levels that STAI could explain is already captured by the other variables, or STAI might not be a relevant predictor for NGF levels in this specific context. Another possible explanation could be that adding STAI could actually decrease the effectiveness of the other variables in the model by introducing noise.

# Problem 3

```{r}
rails = read_excel("./Rails.xlsx")
head(rails)
```

## Part (a)

```{r}
model1 = lm(price2014 ~ distance + squarefeet + no_rooms + no_full_baths + walkscore, data = rails)
summarym1 <- summary(model1)
summarym1
```

Sample Regression Equation: $\hat{Y} = 9.4664 + 2.9434X_1 + 116.1915X_2 + 2.5481X_3 + 29.2217X_4 + 1.0048X_5$, where $\hat{Y}$ is the predicted price of the house in 2014 in thousands of dollars and $X_1$, $X_2$, $X_3$, $X_4$, and $X_5$ are the distance, square feet, number of rooms, number of full baths, and walk score of the house respectively.

Population Regression Equation: $Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_3 + \beta_4X_4 + \beta_5X_5 + \epsilon$, where $Y$ is the price of the house in 2014 in thousands of dollars, $X_1$, $X_2$, $X_3$, $X_4$, and $X_5$ are the distance, square feet, number of rooms, number of full baths, and walk score of the house respectively, $\beta_0, \beta_1, \beta_2, \beta_3, \beta_4, \beta_5$ are the population parameters, and $\epsilon$ is the error term.

## Part (b)

```{r}
summarym1$sigma
```

s = 62.507 means that the average difference between the observed values and the predicted values is 62.507. Also we expect 95% of the differences to be within 125.014 (2s) of the predicted value.

```{r}
summarym1$r.squared
```

0.698 means that 69.8% of the variability in the price of the house in 2014 can be explained by the distance, square feet, number of rooms, number of full baths, and walk score of the house.

## Part (c)

116.1915 is the predicted increase in the price of the house in 2014 in thousands of dollars for every additional square foot of the house, holding all other predictors constant. 1.0048 is the predicted increase in the price of the house in 2014 in thousands of dollars for every additional walk score of the house, holding all other predictors constant.

## Part (d)

```{r}
par(mfrow=c(2,4)) 
plot(resid(model1)~fitted(model1),ylab="Residuals",xlab="Fitted",pch=19)
abline(h=0,lty=2)

plot(resid(model1)~distance, data=rails,ylab="Residuals",pch=19)
abline(h=0,lty=2)

plot(resid(model1)~squarefeet,data=rails,ylab="Residuals",pch=19)
abline(h=0,lty=2)

plot(resid(model1)~no_rooms,data=rails,ylab="Residuals",pch=19)
abline(h=0,lty=2)

plot(resid(model1)~no_full_baths,data=rails,ylab="Residuals",pch=19)
abline(h=0,lty=2)

plot(resid(model1)~walkscore,data=rails,ylab="Residuals",pch=19)
abline(h=0,lty=2)

#normal Q-Q plot and histogram of residuals
qqnorm(resid(model1),ylab="Residuals"); qqline(resid(model1),lty=3)
hist(resid(model1),main="", xlab="Residuals",col='lightblue')
```

```{r}
library('lmtest')
shapiro.test(resid(model1))
bptest(model1)
```

From the residual analysis, the assumption for linearity has not been violated since the qq plot has no deviations from the line, although there is a presence of an outlier. There does seem to be a violation for the assumption of equal variance since when taking a look at the residuals vs distance plot there is a fan shape. That patter can also be seen in the no_rooms vs residuals plot. This is further reinforced by the Breusch-Pagan test which resulted in a p value \< 0.001, which means there is sufficient evidence to reject the null that assumption of equal variance has been violated. For the assumption of normality, the Shapiro-Wilk test that was conducted resulted in significant results, which means the assumptions has been violated however this could be due to the outlier. Taking a look at the distribution of the residuals vs frequency histogram shows a plot which would be normal without the outlier.

## Part (e)

**Model-Utility Test**

$H_0$: $\beta_1 = \beta_2 = \beta_3 = \beta_4 = \beta_5 = 0$.

$H_a$: At least one of $\beta_1$, $\beta_2$, $\beta_3$, $\beta_4$, or $\beta_5$ $\neq$ 0.

$\beta_1$, $\beta_2$, $\beta_3$, $\beta_4$, and $\beta_5$ are the coefficients for distance, square feet, number of rooms, number of full baths, and walk score of the house respectively.

```{r}
summarym1
```

Test Statistic: F-statistic is 45.23

Degrees of Freedom: 104 - 6 = 98

p-value: 2.2e-16

Conclusion: Based on the small p-value of 2.2e-16, we have sufficient evidence to reject the Null Hypothesis. We have extremely strong evidence to conclude that one of the $\beta_i$'s (i = 1,...,5) is not equal to 0, and thus, can conclude that at least one of the variables (distance, square feet, number of rooms, number of full baths, and walk score) is a significant predictor of the price of the house in 2014.

## Part (f)

**Single-Coefficient Test on X1 (distance)**

$H_0$: $\beta_1 = 0$

$H_a$: $\beta_1 \neq 0$

$\beta_1$ is the coefficient for distance.

```{r}
summarym1 # or Anova(model1, type='II')
```

Test Statistic: t = 0.283

Degrees of Freedom: 104 - 6 = 98

p-value: 0.7781

Conclusion: Based on the large p-value of 0.7781, we do not have sufficient evidence to reject the null hypothesis. The large p-value implies that we do not have enough evidence to believe that $\beta_1$, which is distance, is any different from zero after adjusting for the other variables (square feet, number of rooms, number of full baths, and walk score of the house). Thus, Distance is not a significant predictor for the model.

## Part (g)

**Single-Coefficient Test on X2 (squarefeet)**

$H_0$: $\beta_2 = 0$

$H_a$: $\beta_2 \neq 0$

$\beta_2$ is the coefficient for square feet.

```{r}
summarym1 # or Anova(model1, type='II')
```

Test Statistic: t = 4.997

Degrees of Freedom: 104 - 6 = 98

p-value: 2.54e-06

Conclusion: Based on the small p-value of 2.54e-06, we have sufficient evidence to reject the null hypothesis. The small p-value implies we have strong evidence to believe that $\beta_2$, which is square feet, is different from zero after adjusting for the other variables (distance, number of rooms, number of full baths, and walk score of the house). Thus, Square feet is a significant predictor of the model.

## Part (h)

**Partial F-Test on X1 and X3, (distance and no_rooms)**

$H_0$: $\beta_1 = \beta_3 = 0$

$H_a$: At least one of $\beta_1$ and $\beta_3 \neq 0$

$\beta_1$ and $\beta_3$ are the coefficients for distance and no_rooms.

```{r}
library(car)

model2 <- lm(price2014 ~ squarefeet + no_full_baths + walkscore, data = rails)
anova(model2, model1)
```

Test Statistic: F-statistic is 0.1208

Degrees of Freedom: 98

p-value: 0.8863

Conclusion: Based on the large p-value, we don't have enough evidence to reject the null hypothesis. Therefore adding these 2 variables, distance and no_rooms, to a model already containing the other 3 variables (square feet, number of full baths, and walk score) does not significantly improve the model. We do not have enough evidence that the full model containing all variables is significantly better than the model with just 3 variables. Thus, we can make the decision to use model2 which drops X1 and X3.

## Part (i)

**Partial F-Test on X3 and X4, (no_rooms and no_full_baths)**

$H_0$: $\beta_3 = \beta_4 = 0$

$H_a$: At least one of $\beta_3$ and $\beta_4 \neq 0$

$\beta_3$ and $\beta_4$ are the coefficients for no_rooms and no_full_baths.

```{r}
library(car)

model3 <- lm(price2014 ~ distance + squarefeet + walkscore, data = rails)
anova(model3, model1)
```

Test Statistic: F-statistic is 3.0247

Degrees of Freedom: 98

p-value: 0.05313

Decision: Reject Null Hypothesis

Conclusion: Based on the p-value of 0.05313, which is greater than our alpha of 0.01, we don't have sufficient evidence to reject the null hypothesis. Therefore adding these 2 variables, no_rooms and no_full_baths, to a model already containing the other 3 variables (distance, square feet, and walk score) does not significantly improve the model. We do not have enough evidence that the full model containing all variables is significantly better than the model with just 3 variables. Thus, we can make the decision to use model3 which drops X3 and X4.

## Part (j)

Model 2 is better than model 1 due to parsimony, which means that the model with fewer parameters is favored over a complex model. We decided this from the p-value from the partial f test, where we failed to reject the null hypothesis that adding variables to the smaller model to form the larger model does not significantly improve the prediction of house price.

## Part (k)

Model 3 is better than model 2. Since both models were rejected due to having p-values greater than our alpha threshold of 0.01, we decided to do a comparison of the p-value and F-statistic between model 1 and 2, and model 1 and 3. The F-statistic for the partial F test for model 3 is 3.0247 and the p-value is 0.05313, while the F-statistic for the partial F test for model 2 is 0.1208 with a p-value of 0.8863. The larger F-statistic and smaller p-value in Model 3 indicates that it explains a larger proportion of the variability in the response variable, house prices in 2014, compared to Model 2.

## Part (l)

```{r}
confint(model1, level = 1 - (1 - 0.95)/5)
```

We are at least 95% confident that the five intervals simultaneously capture their corresponding population coefficients.

# Problem 4

## Part (a)

```{r}
#Import the Data
SweetData=read.table('sweetness.txt',header=TRUE)

# By-hand
model <- lm(SweetIndex ~ Pectin, data = SweetData)
x0 = c(1, 300)
predicted_matrix = model$coefficients %*% x0
print(paste("By-hand:", round(predicted_matrix[1], 5)))

# predict()
predicted_func = predict(model, data.frame(Pectin = 300))
print(paste("Predict():", round(predicted_func[1], 5)))
```

## Part (b)

```{r}
s = summary(model)$sigma
rows = length(SweetData$SweetIndex)
df = rows - 2
tstar = qt(0.975, df = df)

# By-hand calculation
X = matrix(c(rep(1, rows), SweetData$Pectin), nrow = rows)
SE = s * sqrt((t(x0) %*% solve(t(X) %*% X) %*% x0))

ci_lower <- predicted_matrix[1] - tstar * SE
ci_upper <- predicted_matrix[1] + tstar * SE

print(paste("By-hand Confidence Interval:", round(ci_lower, 4), "to", round(ci_upper, 4)))

# predict()
CI <- predict(model, newdata = data.frame(Pectin = 300), interval = "confidence", level = 0.95)
print(paste("Predict() Confidence Interval:", round(CI[2], 4), "to", round(CI[3], 4)))
```

We're 95% confident that the mean sweetness index for all orange juices with 300 ppm of pectin is between 5.4372 and 5.6806.

## Part (c)

```{r}
# By-hand calculation
SE = s * sqrt(1 + (t(x0) %*% solve(t(X) %*% X) %*% x0))

pi_lower <- predicted_matrix[1] - tstar * SE
pi_upper <- predicted_matrix[1] + tstar * SE

print(paste("By-hand Prediction Interval:", round(pi_lower, 4), "to", round(pi_upper, 4)))

# predict()
PI <- predict(model, newdata = data.frame(Pectin = 300), interval = "prediction", level = 0.95)
print(paste("Predict() Prediction Interval:", round(PI[2], 4), "to", round(PI[3], 4)))
```

We're 95% confident that an orange juices with 300 ppm of pectin will have a sweetness index between 5.0967 and 6.0211.

## Part (d)

In Part B, we're calculating the confidence interval, or the average/mean of the response variable, sweetness index, for all pectin values at 300 ppm. The confidence interval only uses the variability of the sample. On the other hand, Part C, uses the prediction interval, which estimates the sweetness index for a particular singular juice at 300 ppm pectin. The prediction interval will use the variability of the sample and the variation of the individual observations at each x value, varying about their mean.

Our results display that the prediction interval is wider than the confidence interval, which supports the statement regarding the additional variability in the prediction interval.
